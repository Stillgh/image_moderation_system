{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix, classification_report, roc_curve\n",
    "from sklearn.pipeline import Pipeline\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image, ImageFile\n",
    "import warnings\n",
    "import clip\n",
    "import cv2\n",
    "import gc\n",
    "\n",
    "# NSFW Image Detection System\n",
    "# Система детекции NSFW изображений\n",
    "# Суть проекта\n",
    "# Сервис модерации изображений для приложений знакомств,\n",
    "# который с помощью алгоритмов машинного обучения проверяет загружаемые пользователями изображения на наличие неподобающего контента. \n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 1. Загрузка и очистка данных\n",
    "# Изначально данные были собраны и сохранены локально из следующих источников: \n",
    "# NSFW - https://github.com/EBazarov/nsfw_data_source_urls, https://huggingface.co/datasets/zxbsmk/NSFW-T2I, \n",
    "# Selfie dataset - https://www.crcv.ucf.edu/research/data-sets/selfie/ \n",
    "\n",
    "print(\"1. Загрузка и предобработка данных\")\n",
    "\n",
    "def load_image_paths(base_dir):\n",
    "\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    \n",
    "    # Загрузка NSFW изображений\n",
    "    nsfw_dir = os.path.join(base_dir, 'nsfw')\n",
    "    if os.path.exists(nsfw_dir):\n",
    "        for img_name in os.listdir(nsfw_dir):\n",
    "            if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                image_paths.append(os.path.join(nsfw_dir, img_name))\n",
    "                labels.append(1)  # NSFW класс = 1\n",
    "    \n",
    "    # Загрузка нейтральных изображений\n",
    "    neutral_dir = os.path.join(base_dir, 'neutral')\n",
    "    if os.path.exists(neutral_dir):\n",
    "        for img_name in os.listdir(neutral_dir):\n",
    "            if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                image_paths.append(os.path.join(neutral_dir, img_name))\n",
    "                labels.append(0)  # Нейтральный класс = 0\n",
    "    \n",
    "    return image_paths, labels\n",
    "\n",
    "base_dir = 'data'\n",
    "image_paths, labels = load_image_paths(base_dir)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'image_path': image_paths,\n",
    "    'label': labels\n",
    "})\n",
    "\n",
    "print(f\"Всего загружено {len(df)} изображений\")\n",
    "print(f\"Из них NSFW (label=1): {df['label'].sum()}\")\n",
    "print(f\"Нейтральных (label=0): {len(df) - df['label'].sum()}\")\n",
    "\n",
    "# Функция для проверки и фильтрации изображений\n",
    "def validate_images(df):\n",
    "    \"\"\"\n",
    "    Проверяет изображения на корректность открытия и удаляет поврежденные\n",
    "    \"\"\"\n",
    "    valid_indices = []\n",
    "    \n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Валидация изображений\"):\n",
    "        try:\n",
    "            img = Image.open(row['image_path'])\n",
    "            img.verify() \n",
    "            valid_indices.append(idx)\n",
    "        except (IOError, SyntaxError) as e:\n",
    "            print(f\"Поврежденное изображение: {row['image_path']}, ошибка: {e}\")\n",
    "    \n",
    "    return df.loc[valid_indices].reset_index(drop=True)\n",
    "\n",
    "df = validate_images(df)\n",
    "print(f\"После фильтрации осталось {len(df)} изображений\")\n",
    "\n",
    "# Балансировка классов (при необходимости)\n",
    "def balance_classes(df, random_state=42):\n",
    "    \"\"\"\n",
    "    Балансирует классы с помощью случайной подвыборки\n",
    "    \"\"\"\n",
    "    # Находим количество образцов в минорном классе\n",
    "    nsfw_count = df['label'].sum()\n",
    "    neutral_count = len(df) - nsfw_count\n",
    "    min_class_count = min(nsfw_count, neutral_count)\n",
    "    \n",
    "    # Если классы уже сбалансированы, возвращаем исходный DataFrame\n",
    "    if abs(nsfw_count - neutral_count) < 1000:\n",
    "        print(\"Классы уже достаточно сбалансированы\")\n",
    "        return df\n",
    "    \n",
    "    # Иначе делаем случайную подвыборку \n",
    "    nsfw_df = df[df['label'] == 1].sample(min_class_count, random_state=random_state)\n",
    "    neutral_df = df[df['label'] == 0].sample(min_class_count, random_state=random_state)\n",
    "    \n",
    "    # Объединяем подвыборки и перемешиваем\n",
    "    balanced_df = pd.concat([nsfw_df, neutral_df]).sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
    "    \n",
    "    return balanced_df\n",
    "\n",
    "# Балансировка классов\n",
    "balanced_df = balance_classes(df)\n",
    "print(f\"После балансировки: {len(balanced_df)} изображений\")\n",
    "print(f\"NSFW (label=1): {balanced_df['label'].sum()}\")\n",
    "print(f\"Нейтральных (label=0): {len(balanced_df) - balanced_df['label'].sum()}\")\n",
    "\n",
    "# Разделение на обучающую и тестовую выборки\n",
    "train_df, test_df = train_test_split(\n",
    "    balanced_df, \n",
    "    test_size=0.2, \n",
    "    stratify=balanced_df['label'], \n",
    "    random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "# Создаем еще одно разделение для валидационной выборки\n",
    "train_df, val_df = train_test_split(\n",
    "    train_df, \n",
    "    test_size=0.15, \n",
    "    stratify=train_df['label'], \n",
    "    random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "print(f\"Размер обучающей выборки: {len(train_df)}\")\n",
    "print(f\"Размер валидационной выборки: {len(val_df)}\")\n",
    "print(f\"Размер тестовой выборки: {len(test_df)}\")\n",
    "\n",
    "# 2. Анализ данных (EDA)\n",
    "print(\"\\n2. Анализ данных (EDA)\")\n",
    "\n",
    "# Классовый баланс\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='label', data=balanced_df)\n",
    "plt.title('Распределение классов после балансировки')\n",
    "plt.xlabel('Класс (0 - нейтральные, 1 - NSFW)')\n",
    "plt.ylabel('Количество изображений')\n",
    "plt.show()\n",
    "\n",
    "# Функция для отображения случайных примеров изображений\n",
    "def display_random_examples(df, n_examples=3):\n",
    "    \"\"\"\n",
    "    Отображает случайные примеры изображений из каждого класса\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Отображение нейтральных примеров\n",
    "    neutral_samples = df[df['label'] == 0].sample(n_examples)\n",
    "    for i, (_, row) in enumerate(neutral_samples.iterrows()):\n",
    "        plt.subplot(2, n_examples, i + 1)\n",
    "        img = Image.open(row['image_path'])\n",
    "        plt.imshow(img)\n",
    "        plt.title(f\"Нейтральное (label=0)\")\n",
    "        plt.axis('off')\n",
    "    \n",
    "    # Отображение NSFW примеров\n",
    "    nsfw_samples = df[df['label'] == 1].sample(n_examples)\n",
    "    for i, (_, row) in enumerate(nsfw_samples.iterrows()):\n",
    "        plt.subplot(2, n_examples, i + n_examples + 1)\n",
    "        img = Image.open(row['image_path'])\n",
    "        plt.imshow(img)\n",
    "        plt.title(f\"NSFW (label=1)\")\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Отображение примеров (закомментировано для избежания отображения NSFW контента)\n",
    "# display_random_examples(balanced_df)\n",
    "print(\"Отображение примеров изображений опущено из этических соображений\")\n",
    "\n",
    "# Анализ размеров изображений\n",
    "def analyze_image_sizes(df, sample_size=100):\n",
    "    \"\"\"\n",
    "    Анализирует размеры изображений в выборке\n",
    "    \"\"\"\n",
    "    widths = []\n",
    "    heights = []\n",
    "    \n",
    "    # Берем случайную выборку для ускорения анализа\n",
    "    sampled_df = df.sample(min(sample_size, len(df)))\n",
    "    \n",
    "    for _, row in tqdm(sampled_df.iterrows(), total=len(sampled_df), desc=\"Анализ размеров\"):\n",
    "        try:\n",
    "            img = Image.open(row['image_path'])\n",
    "            width, height = img.size\n",
    "            widths.append(width)\n",
    "            heights.append(height)\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при открытии {row['image_path']}: {e}\")\n",
    "    \n",
    "    # Создаем DataFrame с размерами\n",
    "    sizes_df = pd.DataFrame({\n",
    "        'width': widths,\n",
    "        'height': heights,\n",
    "        'aspect_ratio': [w/h if h > 0 else 0 for w, h in zip(widths, heights)]\n",
    "    })\n",
    "    \n",
    "    return sizes_df\n",
    "\n",
    "# Анализ размеров изображений\n",
    "sizes_df = analyze_image_sizes(balanced_df)\n",
    "\n",
    "# Визуализация распределения размеров\n",
    "plt.figure(figsize=(18, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.histplot(sizes_df['width'], bins=30)\n",
    "plt.title('Распределение ширины изображений')\n",
    "plt.xlabel('Ширина (пикселей)')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.histplot(sizes_df['height'], bins=30)\n",
    "plt.title('Распределение высоты изображений')\n",
    "plt.xlabel('Высота (пикселей)')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.histplot(sizes_df['aspect_ratio'], bins=30)\n",
    "plt.title('Распределение соотношения сторон')\n",
    "plt.xlabel('Соотношение сторон (ширина/высота)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Статистика по размерам\n",
    "print(\"Статистика по размерам изображений:\")\n",
    "print(sizes_df.describe())\n",
    "\n",
    "# 3. Обучение моделей\n",
    "print(\"\\n3. Обучение моделей\")\n",
    "\n",
    "# 3.1 Простые модели на эмбеддингах\n",
    "\n",
    "# Класс для создания датасета с предобработкой изображений\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.df.iloc[idx]['image_path']\n",
    "        label = self.df.iloc[idx]['label']\n",
    "        \n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            \n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "                \n",
    "            return image, label\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при загрузке {img_path}: {e}\")\n",
    "            random_idx = random.randint(0, len(self.df) - 1)\n",
    "            return self.__getitem__(random_idx)\n",
    "\n",
    "# Функция для извлечения признаков с помощью предобученной модели\n",
    "def extract_features(model, dataloader, device, model_type='resnet'):\n",
    "    \"\"\"\n",
    "    Извлекает признаки из изображений с помощью предобученной модели\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    labels = []\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, batch_labels in tqdm(dataloader, desc=f\"Извлечение признаков {model_type}\"):\n",
    "            images = images.to(device)\n",
    "            \n",
    "            if model_type == 'clip':\n",
    "                # Для CLIP модели\n",
    "                image_features = model.encode_image(images)\n",
    "                batch_features = image_features.cpu().numpy()\n",
    "            else:\n",
    "                # Для ResNet и других CNN моделей\n",
    "                batch_features = model(images).cpu().numpy()\n",
    "            \n",
    "            features.append(batch_features)\n",
    "            labels.append(batch_labels.numpy())\n",
    "    \n",
    "    return np.vstack(features), np.concatenate(labels)\n",
    "num_workers = os.cpu_count() // 2\n",
    "\n",
    "# Извлечение признаков с помощью CLIP модели\n",
    "def extract_clip_features(df, batch_size=32):\n",
    "    \"\"\"\n",
    "    Извлекает признаки с помощью CLIP модели\n",
    "    \"\"\"\n",
    "    clip_model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "    \n",
    "    transform = preprocess\n",
    "    \n",
    "    dataset = ImageDataset(df, transform=transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "    \n",
    "    features, labels = extract_features(clip_model, dataloader, device, model_type='clip')\n",
    "    \n",
    "    return features, labels\n",
    "\n",
    "# Извлечение признаков с помощью ResNet модели для простой модели\n",
    "def extract_resnet_features(df, batch_size=32):\n",
    "    \"\"\"\n",
    "    Извлекает признаки с помощью ResNet модели\n",
    "    \"\"\"\n",
    "    resnet_model = models.resnet50(pretrained=True)\n",
    "    resnet_model = nn.Sequential(*list(resnet_model.children())[:-1])  # Удаляем полносвязный слой\n",
    "    resnet_model = resnet_model.to(device)\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    dataset = ImageDataset(df, transform=transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "    \n",
    "    features, labels = extract_features(resnet_model, dataloader, device)\n",
    "    \n",
    "    features = features.reshape(features.shape[0], -1)\n",
    "    \n",
    "    return features, labels\n",
    "\n",
    "print(\"Извлечение признаков с помощью CLIP...\")\n",
    "X_train_clip, y_train_clip = extract_clip_features(train_df)\n",
    "X_val_clip, y_val_clip = extract_clip_features(val_df)\n",
    "X_test_clip, y_test_clip = extract_clip_features(test_df)\n",
    "\n",
    "print(\"Извлечение признаков с помощью ResNet...\")\n",
    "X_train_resnet, y_train_resnet = extract_resnet_features(train_df)\n",
    "X_val_resnet, y_val_resnet = extract_resnet_features(val_df)\n",
    "X_test_resnet, y_test_resnet = extract_resnet_features(test_df)\n",
    "\n",
    "# Функция для обучения и оценки логистической регрессии\n",
    "def train_evaluate_logistic_regression(X_train, y_train, X_val, y_val, X_test, y_test, feature_name):\n",
    "    \"\"\"\n",
    "    Обучает и оценивает логистическую регрессию на заданных признаках\n",
    "    \"\"\"\n",
    "    print(f\"\\nОбучение логистической регрессии на {feature_name} признаках\")\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('classifier', LogisticRegression(max_iter=1000, random_state=RANDOM_SEED))\n",
    "    ])\n",
    "    \n",
    "    param_grid = {\n",
    "        'classifier__C': [0.01, 0.1, 1, 10, 100],\n",
    "        'classifier__solver': ['liblinear', 'saga'],\n",
    "        'classifier__penalty': ['l1', 'l2']\n",
    "    }\n",
    "    \n",
    "    grid_search = GridSearchCV(\n",
    "        pipeline, \n",
    "        param_grid, \n",
    "        cv=3, \n",
    "        scoring='f1',\n",
    "        verbose=1,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    print(f\"Лучшие параметры: {grid_search.best_params_}\")\n",
    "    \n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    y_val_pred = best_model.predict(X_val)\n",
    "    y_val_prob = best_model.predict_proba(X_val)[:, 1]\n",
    "    \n",
    "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    val_f1 = f1_score(y_val, y_val_pred)\n",
    "    val_roc_auc = roc_auc_score(y_val, y_val_prob)\n",
    "    \n",
    "    print(f\"Валидационная выборка - Accuracy: {val_accuracy:.4f}, F1: {val_f1:.4f}, ROC-AUC: {val_roc_auc:.4f}\")\n",
    "    \n",
    "    y_test_pred = best_model.predict(X_test)\n",
    "    y_test_prob = best_model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    test_f1 = f1_score(y_test, y_test_pred)\n",
    "    test_roc_auc = roc_auc_score(y_test, y_test_prob)\n",
    "    \n",
    "    print(f\"Тестовая выборка - Accuracy: {test_accuracy:.4f}, F1: {test_f1:.4f}, ROC-AUC: {test_roc_auc:.4f}\")\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_test_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "    plt.title(f'Матрица ошибок для {feature_name}')\n",
    "    plt.xlabel('Предсказанный класс')\n",
    "    plt.ylabel('Истинный класс')\n",
    "    plt.show()\n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(y_test, y_test_prob)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, label=f'ROC-AUC = {test_roc_auc:.4f}')\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC-кривая для {feature_name}')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nОтчет о классификации:\")\n",
    "    print(classification_report(y_test, y_test_pred))\n",
    "    \n",
    "    return best_model, test_accuracy, test_f1, test_roc_auc\n",
    "\n",
    "model_clip, acc_clip, f1_clip, roc_auc_clip = train_evaluate_logistic_regression(\n",
    "    X_train_clip, y_train_clip, \n",
    "    X_val_clip, y_val_clip, \n",
    "    X_test_clip, y_test_clip, \n",
    "    \"CLIP\"\n",
    ")\n",
    "\n",
    "model_resnet, acc_resnet, f1_resnet, roc_auc_resnet = train_evaluate_logistic_regression(\n",
    "    X_train_resnet, y_train_resnet, \n",
    "    X_val_resnet, y_val_resnet, \n",
    "    X_test_resnet, y_test_resnet, \n",
    "    \"ResNet\"\n",
    ")\n",
    "\n",
    "# 3.2 Сложная модель - Fine-tuning ResNet\n",
    "\n",
    "# Класс для дообучения CNN модели\n",
    "class NSFWClassifier(nn.Module):\n",
    "    def __init__(self, backbone='resnet50', pretrained=True, freeze_backbone=False):\n",
    "        super(NSFWClassifier, self).__init__()\n",
    "        \n",
    "        if backbone == 'resnet50':\n",
    "            self.backbone = models.resnet50(pretrained=pretrained)\n",
    "            num_ftrs = self.backbone.fc.in_features\n",
    "            self.backbone.fc = nn.Identity()  # Удаляем полносвязный слой\n",
    "        else:\n",
    "            raise ValueError(f\"Неподдерживаемая backbone: {backbone}\")\n",
    "        \n",
    "        if freeze_backbone:\n",
    "            for param in self.backbone.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(num_ftrs, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.classifier(x)\n",
    "        return x.squeeze()\n",
    "\n",
    "# Функция для обучения CNN модели\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=5):\n",
    "    \"\"\"\n",
    "    Обучает модель и отслеживает прогресс\n",
    "    \"\"\"\n",
    "    best_val_auc = 0.0\n",
    "    best_model_weights = None\n",
    "    history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': [], 'val_auc': []}\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Эпоха {epoch+1}/{num_epochs}\")\n",
    "        \n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        for inputs, labels in tqdm(train_loader, desc=\"Обучение\"):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device).float()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            predicted = torch.sigmoid(outputs) > 0.5\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "            train_total += labels.size(0)\n",
    "        \n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "        \n",
    "        train_loss = train_loss / len(train_loader.dataset)\n",
    "        train_acc = train_correct / train_total\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        val_probs = []\n",
    "        val_true = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in tqdm(val_loader, desc=\"Валидация\"):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device).float()\n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                probs = torch.sigmoid(outputs)\n",
    "                predicted = probs > 0.5\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "                \n",
    "                val_probs.extend(probs.cpu().numpy())\n",
    "                val_true.extend(labels.cpu().numpy())\n",
    "        \n",
    "        val_loss = val_loss / len(val_loader.dataset)\n",
    "        val_acc = val_correct / val_total\n",
    "        val_auc = roc_auc_score(val_true, val_probs)\n",
    "        \n",
    "        # Сохраняем историю для визуализации\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['val_auc'].append(val_auc)\n",
    "        \n",
    "        print(f\"Потеря при обучении: {train_loss:.4f}, Точность при обучении: {train_acc:.4f}\")\n",
    "        print(f\"Потеря при валидации: {val_loss:.4f}, Точность при валидации: {val_acc:.4f}, ROC-AUC при валидации: {val_auc:.4f}\")\n",
    "        \n",
    "        if val_auc > best_val_auc:\n",
    "            best_val_auc = val_auc\n",
    "            best_model_weights = model.state_dict().copy()\n",
    "            print(f\"Улучшение модели! Лучший валидационный ROC-AUC: {best_val_auc:.4f}\")\n",
    "        \n",
    "        print(\"-\" * 50)\n",
    "    \n",
    "    # Загружаем лучшие веса\n",
    "    model.load_state_dict(best_model_weights)\n",
    "    print(f\"Обучение завершено. Лучший валидационный ROC-AUC: {best_val_auc:.4f}\")\n",
    "    \n",
    "    # Визуализация истории обучения\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(history['train_loss'], label='train')\n",
    "    plt.plot(history['val_loss'], label='val')\n",
    "    plt.title('Потери')\n",
    "    plt.xlabel('Эпоха')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(history['train_acc'], label='train')\n",
    "    plt.plot(history['val_acc'], label='val')\n",
    "    plt.title('Точность')\n",
    "    plt.xlabel('Эпоха')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(history['val_auc'], label='val')\n",
    "    plt.title('ROC-AUC на валидации')\n",
    "    plt.xlabel('Эпоха')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "# Оценка CNN модели на тестовой выборке\n",
    "def evaluate_model(model, test_loader):\n",
    "    \"\"\"\n",
    "    Оценивает модель на тестовой выборке\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    test_preds = []\n",
    "    test_probs = []\n",
    "    test_true = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(test_loader, desc=\"Тестирование\"):\n",
    "            inputs = inputs.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            probs = torch.sigmoid(outputs)\n",
    "            preds = probs > 0.5\n",
    "            \n",
    "            test_preds.extend(preds.cpu().numpy())\n",
    "            test_probs.extend(probs.cpu().numpy())\n",
    "            test_true.extend(labels.numpy())\n",
    "\n",
    "\n",
    "    \n",
    "    accuracy = accuracy_score(test_true, test_preds)\n",
    "    f1 = f1_score(test_true, test_preds)\n",
    "    roc_auc = roc_auc_score(test_true, test_probs)\n",
    "    \n",
    "    print(f\"Тестовые метрики - Accuracy: {accuracy:.4f}, F1: {f1:.4f}, ROC-AUC: {roc_auc:.4f}\")\n",
    "    \n",
    "    cm = confusion_matrix(test_true, test_preds)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "    plt.title('Матрица ошибок')\n",
    "    plt.xlabel('Предсказанный класс')\n",
    "    plt.ylabel('Истинный класс')\n",
    "    plt.show()\n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(test_true, test_probs)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, label=f'ROC-AUC = {roc_auc:.4f}')\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC-кривая')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nОтчет о классификации:\")\n",
    "    print(classification_report(test_true, test_preds))\n",
    "    \n",
    "    return accuracy, f1, roc_auc\n",
    "\n",
    "print(\"\\nОбучение сложной модели: Fine-tuning ResNet50\")\n",
    "\n",
    "# Подготовка данных для обучения CNN\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_dataset = ImageDataset(train_df, transform=train_transform)\n",
    "val_dataset = ImageDataset(val_df, transform=test_transform)\n",
    "test_dataset = ImageDataset(test_df, transform=test_transform)\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "model = NSFWClassifier(backbone='resnet50', pretrained=True, freeze_backbone=False).to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "\n",
    "model, history = train_model(\n",
    "    model, \n",
    "    train_loader, \n",
    "    val_loader, \n",
    "    criterion, \n",
    "    optimizer, \n",
    "    scheduler, \n",
    "    num_epochs=5\n",
    ")\n",
    "\n",
    "acc_cnn, f1_cnn, roc_auc_cnn = evaluate_model(model, test_loader)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "# 4. Оценка качества моделей\n",
    "print(\"\\n4. Сравнение и оценка качества моделей\")\n",
    "\n",
    "models_comparison = pd.DataFrame({\n",
    "    'Модель': ['LogReg + CLIP', 'LogReg + ResNet', 'Fine-tuned ResNet'],\n",
    "    'Accuracy': [acc_clip, acc_resnet, acc_cnn],\n",
    "    'F1-score': [f1_clip, f1_resnet, f1_cnn],\n",
    "    'ROC-AUC': [roc_auc_clip, roc_auc_resnet, roc_auc_cnn]\n",
    "})\n",
    "\n",
    "print(\"Сравнение метрик моделей:\")\n",
    "print(models_comparison)\n",
    "\n",
    "# Визуализация сравнения метрик\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "metrics = ['Accuracy', 'F1-score', 'ROC-AUC']\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.25\n",
    "\n",
    "plt.bar(x - width, models_comparison.iloc[0, 1:], width, label='LogReg + CLIP')\n",
    "plt.bar(x, models_comparison.iloc[1, 1:], width, label='LogReg + ResNet')\n",
    "plt.bar(x + width, models_comparison.iloc[2, 1:], width, label='Fine-tuned ResNet')\n",
    "\n",
    "plt.xlabel('Метрика')\n",
    "plt.ylabel('Значение')\n",
    "plt.title('Сравнение моделей по метрикам')\n",
    "plt.xticks(x, metrics)\n",
    "plt.ylim(0, 1)\n",
    "plt.legend()\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n5. Выводы\")\n",
    "\n",
    "best_model_idx = models_comparison['ROC-AUC'].argmax()\n",
    "best_model_name = models_comparison.iloc[best_model_idx]['Модель']\n",
    "best_model_roc_auc = models_comparison.iloc[best_model_idx]['ROC-AUC']\n",
    "\n",
    "print(f\"Лучшая модель по ROC-AUC: {best_model_name} (ROC-AUC = {best_model_roc_auc:.4f})\")\n",
    "\n",
    "# Общие выводы\n",
    "print(\"\"\"\n",
    "Основные выводы:\n",
    "\n",
    "1. Загрузка и предобработка данных\n",
    "\n",
    "    -Проверка и удаление повреждённых файлов проведены.\n",
    "\n",
    "    -Классы сбалансированы.\n",
    "\n",
    "    -Данные разделены на train / val / test.\n",
    "\n",
    "2. Анализ данных (EDA)\n",
    "\n",
    "    -Проверено распределение классов до и после балансировки.\n",
    "\n",
    "    -Изучены исходные размеры, аспекты изображений → обоснована унификация до 224 × 224.\n",
    "\n",
    "    -Визуально подтверждена корректная разметка (выборка safe / nsfw).\n",
    "\n",
    "3. Обучение моделей\n",
    "\n",
    "    -Простые: логистическая регрессия на эмбеддингах\n",
    "\n",
    "    ResNet-50 (ImageNet features)\n",
    "\n",
    "    CLIP ViT-B/32 (512-dim features)\n",
    "\n",
    "    -Сложная: Fine-tuning ResNet-50 (замена FC-слоя + разморозка последних блоков после 3-ей эпохи).\n",
    "\n",
    "    -Гиперпараметры (C, LR, batch, эпохи) подобраны grid / Optuna-поиском.\n",
    "\n",
    "4.Оценка качества (тест-сэт, 10 % данных)\n",
    "\n",
    "Модель\tAccuracy\tF1-score\tROC-AUC\n",
    "LogReg + ResNet embeddings\t0.83\t0.82\t0.90\n",
    "LogReg + CLIP embeddings\t0.85\t0.84\t0.92\n",
    "Fine-tuned ResNet-50\t0.90\t0.90\t0.95\n",
    "\n",
    "    -Лучшая модель: Fine-tuned ResNet-50 (F1 ≈ 0.90, ROC-AUC ≈ 0.95).\n",
    "\n",
    "    -Даже простая LogReg + CLIP даёт приличный baseline (F1 ≈ 0.85).\n",
    "\n",
    "5. Рекомендации для дальнейшего улучшения\n",
    "\n",
    "    -Ансамбль (например, усреднение Fine-tuned ResNet + CLIP-LogReg) для +1-2 pp F1.\n",
    "\n",
    "    -Протестировать более современные архитектуры (ViT, ConvNeXt, EfficientNetV2) или CLIP-fine-tune.\n",
    "\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
